title: 从JIMI的FAQ谈现有的聊天机器人限制
type: post
date: 2017-02-13 00:44:47
category: 
---

## 一切从一份诚实的FAQ开始

关于JIMI聊天机器人，你们看它的FAQ https://help.jd.com/user/issue/316-977.html 就能看出现在的聊天机器人的限制。这个里面所列的技巧，就是请求用户按照这种方式说话，为什么呢？我来翻译一下

技巧一：省略问候语。

也就是说机器人的上下文分析能力很弱，同时问候语增加了噪音，降低了模板匹配成功率（其实所谓DeepQA的匹配和模板匹配依然差不多）

技巧二：问题简洁明了，避免冗长。

这条依然是怕用户的问题太长，噪音太多，降低匹配成功率。

技巧三：一次性提问完整，避免一个问题分两次发送。

这个“技巧”是告诉大家，机器人的上下文处理能力很弱很弱，例如你问“上海天气怎么样”，机器人会回答，如果你分成两句，第一句：“你告诉我些天气信息吧”，第二句：“上海的”，那机器人就萌逼了。

技巧四：一次发送一个问题，避免一个问题里包含两个提问。

机器人能准确回答一个问题就已经很难为它了，你还想一句话问两件事儿，你想疯啊？

技巧五：发起咨询内容应尽量减少错别字，否则JIMI可能无法识别.。

模板匹配，模板匹配，模板匹配。（这句FAQ后面有一个英文句号，原网址就有，至少现在有，呵呵）

技巧六：快捷查询。

求求你，能快速查询的东西点按钮好伐？不要问我啦？我准确率其实没那么高的。我因为准确率没那么高才要你去按按钮啊，写表单啊之类的，能别问就别问。

技巧七：客户问题引导。

这种是一种假上下文模式，就是将用户带入一个故事，例如用户说：“我想买披萨”，机器人就可能进入这种模式，然后接下来问你一系列的：“多大？”，“什么料”，“要饮料吗”，这种用户story是很多常见的机器人平台的做法，因为你直接说一个“我想要一个12寸的夏威夷披萨多放酱油”，机器人需要识别其中的内容太多（例如12寸，夏威夷，酱油），技术难度太高。

技巧八：JIMI处理范畴。

我们是“人工，智能”，如果智能错了，我们马上接人工，谢谢不客气。

总结：从JIMI的FAQ就能看出来它的限制，我只能说京东还是非常的诚实的。我是相信京东的技术是业界领先水平（有钱就有技术，不要质疑这一点）。但是在现有技术下很多功能无法完成的，你让京东怎么办？他只能很诚实的告诉你“技巧”好伐？

## 聊天机器人背后的技术

搜索一些关于JIMI的内容，能搜索到这样一篇文章，例如 http://news.163.com/16/0325/17/BJ14NPAA000146BE.html 。里面提到了JIMI用了深度学习啦，DeepQA啦，呵呵。其实这个很简单的，至少这个文章里面的流程图（虽然这个文章很老）里面的这种所谓DeepQA的系统很简单。就是把问题向量化（就好像word2vec是词向量化，我们想办法做句子向量化），然后把所有答案向量化，再去根据向量距离寻找答案。或者直接把问题答案丢到一个模型里，本质也是在模型内部向量化。向量化的目的就是为了寻找问题和答案的相关性，我们就可以定义一个距离，例如问题和答案配对的越好，距离越近。或者问题和机器人平台已经有的问题越近似，距离越近。从而找到一个用户输入问题的最近似答案。

这样的论文其实不少，例如用LSTM的 https://arxiv.org/abs/1511.04108 ，用CNN的 https://www.aclweb.org/anthology/P/P15/P15-2114.pdf

这种本质是什么？本质就是相似性的检索。最简单的相似性检索（问题到相似问题），是直接使用“编辑距离”，Levenshtein距离。例如：“今天天气不错”和“天气不错”的编辑距离是2，因为前一句去掉两个字（有两个编辑改动）就可以变为第二句。当然最简单的编辑距离有很多问题，例如“我爱你”和“我恨你”的编辑距离只有1，系统很可能认为它们是相似句子。

现有的DeepQA的学术研究，都没能真正解决语义上的相似性，这种模型可能不会认为“我爱你”与“我恨你”是相似的，但是它很可能会认为“你知道吗，我有一句话不知道当讲不当讲，憋了很久才鼓起勇气告诉你，我爱你”和“你知道吗，我有一句话不知道当讲不当讲，憋了很久才鼓起勇气告诉你，我恨你”是相似的。

更何况是现实中我们还需要加入上下文了。从连接主义（深度学习）去思考，就连word2vec的能力界限在哪都不清楚，否则也就不会还有fasttext，glove之类的研究了，因为各自的训练出的语义信息很不稳定，也很难真正解释它们背后的含义。句子的语义相似度更是无底洞，Bengio似乎一直在尝试（包括14年发表的Sequence to Sequence Learning）也是尝试的成果之一 (https://arxiv.org/pdf/1406.1078.pdf)，论文中就提到了关于句子的语义表示的问题，但是没给出能应用这种表示的意义。

说到Sequence to Sequence Learning，例如这篇文章 http://www.leiphone.com/news/201702/O9PGyImfH1Vq3fxV.html 提到了它作为chatbot的一种模型。深不以为然，我不相信现在真有这样的服务做出来，因为Sequence to Sequence直接用于答案生成准确率太低了，结果很难控制，而且也很难找到一个足够好的训练集去训练，如果你真的有这样足够好的训练集，用什么方法不行，非得用这种方法吗？这种方法作用于QA系统最早也是谷歌的论文 https://arxiv.org/abs/1506.05869 不过那个结果已经就看不出来好了。后续虽然有各种论文通过加入强化学习，改进模型等等的研究，包括百度也做过基于贴吧数据集的Sequence to Sequence研究，但是结果都不可能达到能商用的地步。

作者原来曾经尝试过Sequence to Sequence Learning在大量数据集上的效果（https://github.com/qhduan/Seq2Seq_Chatbot_QA），结论是，数据集不是越大越好，还是越准越好。例如在射手网所有中文字幕集（提取了3亿对上下文对话），结果反而不如中间很小一部分数据产生出的模型，例如这份语料（https://github.com/rustch3n/dgk_lost_conv）

## 我们还是原始人

最终现在所有的聊天机器人构架，都是基于非常有限的上下文信息的规则匹配系统，为了达到可能实用的程度，它有非常多的工程组件用来解决用户体验问题。本质这些都没有什么太高深的技术，但是能搭建起来一个完整的工程系统本身还是有难度的，否则中国就不会只有世纪佳缘的“一个AI”抄袭的那么好了。至于图灵机器人，其实根本不算是机器人平台，它连写一个完整的用户story的能力都没有（参考上面披萨的例子）。

Deep Learning也许会成为这个规则系统中的某个组成部分，成为各大厂商吹嘘的对象，但是它本身不是黑魔法，能力也很弱很弱，需要学术界和同业界一起不断的发展才行。

这种聊天机器人有多有用，我认为还是有待市场验证的问题。希望我们早日脱离“原始社会”，走向技术新时代吧。
