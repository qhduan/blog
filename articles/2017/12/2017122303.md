title: 聊天机器人《RubyStar: A Non-Task-Oriented Mixture Model Dialog System》论文简析
type: post
date: 2017-12-23 03:44:34
category: read paper
edit: 2017-12-23 03:57:46
---

背景：这篇论文是卡耐基梅隆大学团队构建的一个名为RubyStar的聊天机器人系统。和亚马逊的Alexa Prize有关系，就是那个智能音箱，亚马逊举办了个类似比赛的东西，也类似基金的感觉我就不清楚了。当然这不代表这个系统就是alexa背后的机制有绝对关系。

## 自然语言理解部分（NLU）

这部分按照论文做了三件重要的事，话题检测（Topic Detection），意图识别（Intent Analysis），实体链接（Entity Linking）

#### 话题检测

数据集使用Reddit评论，把用户的输入转换为词向量，然后经过一个20棵树的随机森林，选出用户输入所在的话题，例如政治、生活、体育、娱乐、一般话题等等分类。

这个话题的分类也应该会影响后续选择如何回答用户的分类依据。

#### 意图识别

意图识别是从另一个角度来分类用户输入，就是判断用户可能想要的回答类型，例如：

- 是或否，类型的回答
- 寻求某个具体事实，姚明的身高？
- 寻求建议
- 喜欢的食物

#### 实体链接

实体链接是从用户输入中提取重要实体，并把这个实体连接到某个类似知识图谱的语义网结构里，论文里是通过TAGME连接到wikipedia

这部分也是为了进行一些模板式回答

例子（和论文里面的不一样，我随便说的）

用户输入：我喜欢钢铁侠，你喜欢什么？
实体：钢铁侠
超级英雄的知识图谱例如包括三元组：<钢铁侠, has friend, 蜘蛛侠>
模板：我喜欢<entity>的朋友<has friend>
输出：我喜欢钢铁侠的朋友蜘蛛侠

模板是针对<has friend>这个关系（relation）来做的，所以假设不是钢铁侠，而是其他的entity，只要有has friend，也应该能匹配到这个模板，例如：

用户输入：我喜欢炸酱面
实体：炸酱面
超级英雄的知识图谱例如包括三元组：<炸酱面, has friend, 腊八蒜>
模板：我喜欢<entity>的朋友<has friend>
输出：我喜欢炸酱面的朋友腊八蒜

## 多种回答模块

#### 模板式回答

就刚才实体链接里那样，不重复

#### 信息检索

根据用户输入的实体，和实体链接的结果，去推特上搜。然后去掉重复、拼写错误、比较无聊的推特之后，按照某个算法排序并返回推特的一句、一段，或者什么，论文没说的太细。

#### 神经网络生成

使用sequence to sequence的深度学习模型，生成一个回答。

这种模型的缺点是，经常会生成“我不知道”，“谢谢你”，这样比较没用的模型（中文也类似，我试过）

基本上也就是在没啥好回答的时候，随便编排编排救个场。

## 选择结果

就是从上面的那些不同模型，选一个答案出来。

论文对比测试了：逻辑回归，线性SVM，朴素贝叶斯三种模型，效果差不多

输入是词袋模型（bag of words）

最后用一个模型的confidence score作为上面的几种回答模型的得分

## 上下文跟踪（Context Tracking）

使用最近N条聊天记录，和斯坦福的CoreNLP工具来追踪上下文代指，例如：

用户：你知道中国吗？
bot：我知道
用户：你知道它的首都吗？
bot：？？？（这里需要知道，它，指的是中国）

## 结尾

整篇论文提到了不少数据集，方法，和trick，还是蛮有趣的

不过很多的细节和trick都是针对为了通用域，更拟人化，让人觉得跟机器瞎聊不太无聊而设计的。笔者觉得通用域聊天机器人没什么太大意义，所以很多trick对于垂直的聊天机器人没什么参考意义。

不过整体构建思路应该还是值得参考的。