title: 机器学习和UFLDL初学有感
date: 2013-05-19 00:54:32
---

记录一些这两天看论文、教程和书的一些小细节，其实都不算是ML和DL了，因为只是看了点BP的皮毛，不过UFLDL最开始也是先介绍BP的，所以大概还有点用。不一定对吧，我感觉里面有很多东西是经验公式。

隐藏层 = Sqrt (输入层 + 输出层) + a
a = 0 ~ 10

上面这个看上去像就是说所谓的Rules of thumb，大拇指原则， 但是实际上实验需要不断尝试

假设输出目标类别为m，输出层至少取log2(m)

一般隐藏层最多两层即可，只有当要学习不连续函数时才需要两层，单层已经可以映射一切连续函数，但是也不绝对。

自适应学习率

if((En / En-1) &gt; k)
{
维持V,M不变，减少学习率
}
else
{
V，W有效，增大学习率
}

训练样本数是网络连接权总数的5~10倍

有本老书建议输出层权值取一半-1，一半1，如果是奇数就另外一个0。这个方法看上去没有UFLDL里面所有都取随机Normal(0, 0.01)的感觉好

最后我发现UFLDL里面的W(l)和Delta(l)和L，根本就有点不相关的意思
L1指输入层，L2指隐藏层，L3指输出层的话
W1指的是隐藏层权值，W2指的是输出层权值
Delta2指的是隐藏层的，Delta3指的是输出层的

好乱好乱……首先根本没有W3和Delta1，但是这两个又是错开的，我想了3天才想明白……笨蛋笨蛋